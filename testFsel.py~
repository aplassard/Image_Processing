from common import *
import fSel, numpy, random
from sklearn import svm
from sklearn.svm import LinearSVC
from MachineLearning.SVM import *

reload(fSel)

def testData(data, labels, perc=0.7):
    '''
    Inputs: features, labels, percent for training
    output: trains an SVM on the data provided and on data after feature selection by
    4 methods and prints the error for each case    
    '''
    #without feature selection
    testX,testY, trainX, trainY=splitTrainingTesting(data, labels, perc)
    print "Testing without feature selection: "
    buildSVM(trainY, trainX, testY, testX)    
    
    #with feature selection
    #univariate, chiSq, k=100
    print "\nTesting feature selection, chiSq, k=100: "
    data_new=fSel.getBestK(data,labels, 'chi2', 100)
    testX,testY, trainX, trainY=splitTrainingTesting(data_new, labels, perc)
    buildSVM(trainY, trainX, testY, testX)    

    #univariate, f_classif, k=100
    print "\nTesting feature selection, f_classif, k=100: "
    data_new=fSel.getBestK(data,labels, 'f_classif', 100)   
    testX,testY, trainX, trainY=splitTrainingTesting(data_new, labels, perc)    
    buildSVM(trainY, trainX, testY, testX)    
    #Tree based
    print "\nTesting feature selection, TreeBased: "
    data_new=fSel.getTreeFeatures(data,labels)
    testX,testY, trainX, trainY=splitTrainingTesting(data_new, labels, perc)    
    buildSVM(trainY, trainX, testY, testX)    

    print "\nTesting feature selection, LinearSVC with L1 penalty: "
    data_new = LinearSVC(C=0.01, penalty="l1", dual=False).fit_transform(data, labels)
    testX,testY, trainX, trainY=splitTrainingTesting(data_new, labels, perc)
    buildSVM(trainY, trainX, testY, testX)    
    
